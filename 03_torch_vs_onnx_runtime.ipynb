{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48cced3f-4d98-4e57-91c7-bab119051e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum[onnxruntime]\n",
      "  Using cached optimum-1.24.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting transformers>=4.29 (from optimum[onnxruntime])\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.11/site-packages (from optimum[onnxruntime]) (2.1.1+cu118)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from optimum[onnxruntime]) (23.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from optimum[onnxruntime]) (1.26.0)\n",
      "Collecting huggingface-hub>=0.8.0 (from optimum[onnxruntime])\n",
      "  Using cached huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting onnx (from optimum[onnxruntime])\n",
      "  Using cached onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime])\n",
      "  Using cached onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting datasets>=1.2.1 (from optimum[onnxruntime])\n",
      "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate (from optimum[onnxruntime])\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting protobuf>=3.20.1 (from optimum[onnxruntime])\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting transformers>=4.29 (from optimum[onnxruntime])\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=1.2.1->optimum[onnxruntime]) (3.9.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting requests>=2.32.2 (from datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=1.2.1->optimum[onnxruntime]) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=1.2.1->optimum[onnxruntime]) (6.0.1)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]) (4.8.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.11.0->optimum[onnxruntime])\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.11.0->optimum[onnxruntime])\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11->optimum[onnxruntime]) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11->optimum[onnxruntime]) (2.1.0)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.29->optimum[onnxruntime])\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.29->optimum[onnxruntime])\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.29->optimum[onnxruntime])\n",
      "  Using cached safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=1.2.1->optimum[onnxruntime]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=1.2.1->optimum[onnxruntime]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=1.2.1->optimum[onnxruntime]) (2023.7.22)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.11.0->optimum[onnxruntime])\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11->optimum[onnxruntime]) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=1.2.1->optimum[onnxruntime])\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->onnxruntime>=1.11.0->optimum[onnxruntime]) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.2.1->optimum[onnxruntime]) (1.16.0)\n",
      "Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Using cached onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Using cached onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "Using cached optimum-1.24.0-py3-none-any.whl (433 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: flatbuffers, xxhash, tzdata, tqdm, safetensors, requests, regex, pyarrow, protobuf, humanfriendly, fsspec, dill, pandas, onnx, multiprocess, huggingface-hub, coloredlogs, tokenizers, onnxruntime, transformers, datasets, optimum, evaluate\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 23.10.0 requires ruamel-yaml<0.18,>=0.11.14, but you have ruamel-yaml 0.18.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed coloredlogs-15.0.1 datasets-3.3.2 dill-0.3.8 evaluate-0.4.3 flatbuffers-25.2.10 fsspec-2024.12.0 huggingface-hub-0.29.1 humanfriendly-10.0 multiprocess-0.70.16 onnx-1.17.0 onnxruntime-1.20.1 optimum-1.24.0 pandas-2.2.3 protobuf-5.29.3 pyarrow-19.0.1 regex-2024.11.6 requests-2.32.3 safetensors-0.5.2 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.48.3 tzdata-2025.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optimum[onnxruntime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd09002b-e594-4314-90ce-da39dffe4f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch output: tensor([[-0.0297, -0.4107, -0.1688, -0.3370,  0.0293]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to ONNX.\n",
      "ONNX Runtime output: [[-0.02971356 -0.4107108  -0.16881287 -0.33697784  0.02931507]]\n",
      "PyTorch inference time over 1000 runs: 0.029034 seconds\n",
      "ONNX Runtime inference time over 1000 runs: 0.008659 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "# Define a simple model: a two-layer MLP\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size=10, hidden_size=20, output_size=5):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model and set to evaluation mode\n",
    "model = SimpleModel()\n",
    "model.eval()\n",
    "\n",
    "# Create a dummy input tensor\n",
    "dummy_input = torch.randn(1, 10)\n",
    "\n",
    "# Run inference using PyTorch\n",
    "with torch.no_grad():\n",
    "    torch_output = model(dummy_input)\n",
    "print(\"PyTorch output:\", torch_output)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "onnx_model_path = \"simple_model.onnx\"\n",
    "torch.onnx.export(model, \n",
    "                  dummy_input, \n",
    "                  onnx_model_path,\n",
    "                  input_names=[\"input\"],\n",
    "                  output_names=[\"output\"],\n",
    "                  opset_version=11)\n",
    "print(\"Model exported to ONNX.\")\n",
    "\n",
    "# Load the ONNX model with ONNX Runtime\n",
    "ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Helper function: convert PyTorch tensor to NumPy array\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# Run inference using ONNX Runtime\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dummy_input)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "print(\"ONNX Runtime output:\", ort_outs[0])\n",
    "\n",
    "# Compare inference speed\n",
    "n_runs = 1000\n",
    "\n",
    "# PyTorch inference timing\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_runs):\n",
    "        _ = model(dummy_input)\n",
    "torch_time = time.time() - start_time\n",
    "\n",
    "# ONNX Runtime inference timing\n",
    "start_time = time.time()\n",
    "for _ in range(n_runs):\n",
    "    _ = ort_session.run(None, ort_inputs)\n",
    "onnx_time = time.time() - start_time\n",
    "\n",
    "print(\"PyTorch inference time over {} runs: {:.6f} seconds\".format(n_runs, torch_time))\n",
    "print(\"ONNX Runtime inference time over {} runs: {:.6f} seconds\".format(n_runs, onnx_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
