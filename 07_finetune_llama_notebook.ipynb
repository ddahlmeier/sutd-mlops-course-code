{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b44ac5-a6e5-4deb-bf47-9daf2db61b1a",
   "metadata": {},
   "source": [
    "# Finetune TinyLlama in Sagemaker notebook \n",
    "\n",
    "In this notebook, we will perform instruction tuning TinyLlama using a subset of the Dolly 15k Dataset.\n",
    "\n",
    "\n",
    "This notebook as been put together based a few great examples and blogs. Feel free to visit them to learn more about finetuning. \n",
    "\n",
    "- [Fourthbrain Repository Building with Instruction-Tuned LLMs: a Step-by-Step Guide](https://github.com/FourthBrain/Building-with-Instruction-Tuned-LLMs-A-Step-by-Step-Guide)\n",
    "- [Notes on fine-tuning Llama 2 using QLoRA: A detailed breakdown. Blog by Ogban Ugot](https://medium.com/@ogbanugot/notes-on-fine-tuning-llama-2-using-qlora-a-detailed-breakdown-370be42ccca1)\n",
    "- [Interactively fine-tune Falcon-40B and other LLMs on Amazon SageMaker Studio notebooks using QLoRA. Blog by AWS](https://aws.amazon.com/blogs/machine-learning/interactively-fine-tune-falcon-40b-and-other-llms-on-amazon-sagemaker-studio-notebooks-using-qlora/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12aa73-eed1-4b34-a578-5bf0fb8b4ec5",
   "metadata": {},
   "source": [
    "### ⚠ IMPORTANT ⚠\n",
    "\n",
    "Please ensure your Jupyterlab instance is set to the following: **ml.g5.4xlarge**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a983a-99df-4cbd-b8fc-cd51a4d48a93",
   "metadata": {},
   "source": [
    "# Development environment\n",
    "\n",
    "We're going to be leveraging a number of awesome tools in order to be able to instruct-tune our model.\n",
    "\n",
    "Here's a brief overview:\n",
    "\n",
    "- [Hugging Face's PEFT Library](https://github.com/huggingface/peft)\n",
    "- [Hugging Face's Transformers Library](https://huggingface.co/docs/transformers/index)\n",
    "- [QLoRA](https://arxiv.org/abs/2305.14314)\n",
    "- [TRL](https://github.com/lvwerra/trl/tree/main/docs/source)\n",
    "\n",
    "Keep in mind that these libraries are being constantly iterated on - and so you may experience bugs/issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3985305a-85aa-48de-a454-9fe506fc8d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft==0.4.0\n",
      "  Using cached peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (2.0.0.post200)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (4.31.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (0.21.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (0.3.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.19.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0) (1.3.0)\n",
      "Using cached peft-0.4.0-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.4.0\n",
      "Collecting bitsandbytes==0.40.2\n",
      "  Using cached bitsandbytes-0.40.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Using cached bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.40.2\n",
      "Requirement already satisfied: transformers==4.31.0 in /opt/conda/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2023.7.22)\n",
      "Collecting trl==0.4.7\n",
      "  Using cached trl-0.4.7-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.4.7) (2.0.0.post200)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.4.7) (4.31.0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.4.7) (1.26.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.4.7) (0.21.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.4.7) (2.14.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.7) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (0.19.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.7) (4.66.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.4.7) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.7) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.7) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.7) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.7) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.7) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->trl==0.4.7) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.7) (3.8.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.7) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.7) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.7) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.4.7) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.4.7) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.7) (1.16.0)\n",
      "Using cached trl-0.4.7-py3-none-any.whl (77 kB)\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.4.7\n",
      "Collecting torch==2.0.1\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1)\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (68.2.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.41.3)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
      "  Using cached cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
      "  Using cached lit-17.0.6-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Using cached cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0.post200\n",
      "    Uninstalling torch-2.0.0.post200:\n",
      "      Successfully uninstalled torch-2.0.0.post200\n",
      "Successfully installed cmake-3.28.1 lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n",
      "Requirement already satisfied: accelerate==0.21.0 in /opt/conda/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.21.0) (68.2.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.21.0) (0.41.3)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0) (3.28.1)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0) (17.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.19.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install peft==0.4.0 \n",
    "! pip install bitsandbytes==0.40.2 \n",
    "! pip install transformers==4.31.0 \n",
    "! pip install trl==0.4.7\n",
    "! pip install torch==2.0.1\n",
    "! pip install accelerate==0.21.0\n",
    "! pip install datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea5caf4-a7d9-41d7-9b3e-4131ce0d9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add installed cuda runtime to path for bitsandbytes\n",
    "import os\n",
    "import nvidia\n",
    "\n",
    "cuda_install_dir = '/'.join(nvidia.__file__.split('/')[:-1]) + '/cuda_runtime/lib/'\n",
    "os.environ['LD_LIBRARY_PATH'] =  cuda_install_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac75ef5b-a947-43bb-8a75-718db642de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 20:25:17.056381: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7f305-bcd6-4ef9-8efc-e6b4eac00162",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5361b-9cdc-4898-923b-7d22c8f499d1",
   "metadata": {},
   "source": [
    "Let's look at our dataset to get an idea of what we're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ba2329-b6ae-43d5-aa50-f4b9f7d969d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dbricks_15k_dataset_base = load_dataset(\"databricks/databricks-dolly-15k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621b461-2c02-4194-b28f-9efc63ac4a0c",
   "metadata": {},
   "source": [
    "Let's check out some brief stats about our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f578c974-939d-4cac-8637-484ccb4dbf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "def plot_and_filter_sequence_lengths(dataset_obj, max_length=2200):\n",
    "\n",
    "    # Initialize a list to store the sequence lengths\n",
    "    sequence_lengths = []\n",
    "\n",
    "    # list of indices that are too long\n",
    "    too_long = []\n",
    "\n",
    "    # Loop over the dataset and get the lengths of text sequences\n",
    "    for idx, example in enumerate(dataset_obj[\"train\"]):\n",
    "        sequence_lengths.append(len(example['instruction']) + len(example[\"context\"]) + len(example[\"response\"]))\n",
    "        if sequence_lengths[idx] > max_length:\n",
    "          too_long.append(idx)\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.hist(sequence_lengths, bins=30)\n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Text Sequence Lengths')\n",
    "    plt.show()\n",
    "\n",
    "    return too_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f5f29c1-9489-41e4-aacd-89b8c0bff1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexes_to_drop = plot_and_filter_sequence_lengths(dbricks_15k_dataset_base, max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f54dd1b-337a-4887-ad85-be2ab5c4f93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3517"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c960bf20-6b6e-4b2b-91be-bab18562d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbricks_15k_dataset_reduced = dbricks_15k_dataset_base[\"train\"].select(\n",
    "    i for i in range(len(dbricks_15k_dataset_base[\"train\"])) if i not in set(indexes_to_drop)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11cd891-055e-4b4d-85c2-dabe16639d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'category'],\n",
       "    num_rows: 11494\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbricks_15k_dataset_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5569c807-3667-442e-9117-100df77e458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbricks_15k_dataset_prepared = dbricks_15k_dataset_reduced.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0454534c-e1d6-4896-bd91-7ec754c7c8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_and_filter_sequence_lengths(dbricks_15k_dataset_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5527d820-82f0-4a0a-ab3b-ec6a5dca9c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category'],\n",
       "        num_rows: 10344\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category'],\n",
       "        num_rows: 1150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbricks_15k_dataset_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef5d6b-e8c7-4d9c-aaa8-bf8b6898ac00",
   "metadata": {},
   "source": [
    "Before we can begin training, we need to set up a few helper functions to ensure our dataset is parsed in the correct format and we save our PEFT adapters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6118dbe-0689-4e20-9ce3-ba2748769872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "  if example.get(\"context\", \"\") != \"\":\n",
    "      input_prompt = (f\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "      \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "      \"### Instruction:\\n\"\n",
    "      f\"{example['instruction']}\\n\\n\"\n",
    "      f\"### Input: \\n\"\n",
    "      f\"{example['context']}\\n\\n\"\n",
    "      f\"### Response: \\n\"\n",
    "      f\"{example['response']}\")\n",
    "\n",
    "  else:\n",
    "    input_prompt = (f\"Below is an instruction that describes a task. \"\n",
    "      \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "      \"### Instruction:\\n\"\n",
    "      f\"{example['instruction']}\\n\\n\"\n",
    "      f\"### Response:\\n\"\n",
    "      f\"{example['response']}\")\n",
    "\n",
    "  return {\"text\" : input_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19b1cf4a-7be1-40f9-8657-14869b99df38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fb76a769e74f62806e93ae038ebfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194de3af6a104f3fac989db5c375c72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "formatted_dataset = dbricks_15k_dataset_prepared.map(formatting_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9f62744-73d1-4d6b-9c45-633cc5a47364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category', 'text'],\n",
       "        num_rows: 10344\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category', 'text'],\n",
       "        num_rows: 1150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df78417b-b196-4a93-8748-2aaeb55453e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'category': 'open_qa',\n",
      "    'context': '',\n",
      "    'instruction': 'Who wrote The History of Mr Polly',\n",
      "    'response': 'H. G. Wells',\n",
      "    'text': 'Below is an instruction that describes a task. Write a response '\n",
      "            'that appropriately completes the request.\\n'\n",
      "            '\\n'\n",
      "            '### Instruction:\\n'\n",
      "            'Who wrote The History of Mr Polly\\n'\n",
      "            '\\n'\n",
      "            '### Response:\\n'\n",
      "            'H. G. Wells'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(formatted_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4307c-06a1-43b1-9e71-e6c3b4517981",
   "metadata": {},
   "source": [
    "Okay, now that we have the Dolly 15k dataset pared down to a more reasonable length - let's set up our model!\n",
    "\n",
    "We'll be leveraging QLoRA for this portion of the notebook, which will ensure a low memory footprint during fine-tuning!\n",
    "\n",
    "- [Paper](https://arxiv.org/pdf/2305.14314.pdf)\n",
    "- [Blog](https://huggingface.co/blog/4bit-transformers-bitsandbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a3f56-ed2f-4d5b-b45c-4cf0afeb56c1",
   "metadata": {},
   "source": [
    "# Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6d9ea2e-f7b9-4cf8-bee9-c72aa69645e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"TinyLlama-1.1B-Chat-dolly\"\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 1\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe6f16-3330-4356-9566-eb6767762675",
   "metadata": {},
   "source": [
    "Now, let's set up our SupervisedFineTuningTrainer and let it rip!\n",
    "\n",
    "More information on the SFTTrainer is available here:\n",
    "\n",
    "- [HF Documentation](https://huggingface.co/docs/trl/main/en/sft_trainer)\n",
    "- [Repository](https://github.com/lvwerra/trl/blob/main/trl/trainer/sft_trainer.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "743fd3e5-e3d7-447e-8d2c-d45efed2c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca64cff97fc3481ab19b4d2ba86236a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c58d0580e047179dc6e28a2aee3c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=formatted_dataset[\"train\"],\n",
    "    eval_dataset=formatted_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5835276e-ac1e-4ec0-8bf1-d711295e4ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb07cbbad70, raw_cell=\"# Train model\n",
      "trainer.train()\n",
      "\n",
      "# Save trained mode..\" store_history=True silent=False shell_futures=True cell_id=5835276e-ac1e-4ec0-8bf1-d711295e4ecd>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2586' max='2586' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2586/2586 10:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.839500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.393400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.355900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.849600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.371900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.945700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.389700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.971700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.456400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.462100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.934200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.413700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.379600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.864600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>1.438300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.878200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>1.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.906600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>1.380100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>1.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.927700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>1.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>1.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>1.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>1.473500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>1.418300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>1.413900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>1.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.922100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>1.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>1.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>1.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>1.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>1.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>1.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>1.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>1.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.876200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>1.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>1.397300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.909900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>1.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>1.319600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.966200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>1.383800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.984100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>1.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>1.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>1.433700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>1.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>1.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.916900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>1.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>1.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>1.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>1.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>1.381300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.903400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>1.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.931200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>1.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.938000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>1.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>1.315800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb07cbbb580, execution_count=35 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb07cbbad70, raw_cell=\"# Train model\n",
      "trainer.train()\n",
      "\n",
      "# Save trained mode..\" store_history=True silent=False shell_futures=True cell_id=5835276e-ac1e-4ec0-8bf1-d711295e4ecd> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413bf59-3ea8-4d1d-af59-7f9ce5d3fdcd",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e719598-be19-4f18-ac76-ec56e670a0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb0fa1c41f0, raw_cell=\"#evaluate and return the metrics\n",
      "trainer.evaluate(..\" store_history=True silent=False shell_futures=True cell_id=2e719598-be19-4f18-ac76-ec56e670a0c1>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.303742527961731,\n",
       " 'eval_runtime': 28.8429,\n",
       " 'eval_samples_per_second': 39.871,\n",
       " 'eval_steps_per_second': 4.993,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb0f87b0df0, execution_count=36 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb0fa1c41f0, raw_cell=\"#evaluate and return the metrics\n",
      "trainer.evaluate(..\" store_history=True silent=False shell_futures=True cell_id=2e719598-be19-4f18-ac76-ec56e670a0c1> result={'eval_loss': 1.303742527961731, 'eval_runtime': 28.8429, 'eval_samples_per_second': 39.871, 'eval_steps_per_second': 4.993, 'epoch': 1.0}>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "#evaluate and return the metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda65b6-85e6-4fb0-bf73-9f2e764dd91c",
   "metadata": {},
   "source": [
    "Load test dataset and try a random sample for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd649520-f1d4-4435-aef5-7b4026ff0ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb0f83dbf40, raw_cell=\"# Ignore warnings\n",
      "logging.set_verbosity(logging.CR..\" store_history=True silent=False shell_futures=True cell_id=dd649520-f1d4-4435-aef5-7b4026ff0ca0>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Who was the first president of Singapore? [/INST]\n",
      "Answer: Lee Kuan Yew\n",
      "Lee Kuan Yew was the first president of Singapore. He was born in Singapore on 22nd January 1926. He was the son of Lee Kuan Yew's father, Lee Kuan Yew's grandfather, and his grandfather's wife. He was the eldest son of Lee Kuan Yew's father, Lee Kuan Yew's grandfather, and his grandfather's wife. He was the eldest son of Lee Kuan Yew's father, Lee Kuan Yew's grandfather, and his grandfather's wife. He was the eldest son of Lee Kuan Yew's father, Lee Kuan Yew's grandfather, and his grandfather's wife. He was the eldest son of Lee Kuan Yew\n",
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb0f83d9f30, execution_count=37 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb0f83dbf40, raw_cell=\"# Ignore warnings\n",
      "logging.set_verbosity(logging.CR..\" store_history=True silent=False shell_futures=True cell_id=dd649520-f1d4-4435-aef5-7b4026ff0ca0> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Who was the first president of Singapore?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1055073b-e296-4014-a8a1-3cdada8961aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb07cbbb580, raw_cell=\"# Empty VRAM\n",
      "del model\n",
      "del pipe\n",
      "del trainer\n",
      "import..\" store_history=True silent=False shell_futures=True cell_id=1055073b-e296-4014-a8a1-3cdada8961aa>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb07cbb95d0, execution_count=38 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb07cbbb580, raw_cell=\"# Empty VRAM\n",
      "del model\n",
      "del pipe\n",
      "del trainer\n",
      "import..\" store_history=True silent=False shell_futures=True cell_id=1055073b-e296-4014-a8a1-3cdada8961aa> result=0>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Empty VRAM\n",
    "del model\n",
    "del pipe\n",
    "del trainer\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "708347ea-040d-4327-9a96-87194109c7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb07cbf0d60, raw_cell=\"# Reload model in FP16 and merge it with LoRA weig..\" store_history=True silent=False shell_futures=True cell_id=708347ea-040d-4327-9a96-87194109c7ca>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb07cbf13c0, execution_count=39 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb07cbf0d60, raw_cell=\"# Reload model in FP16 and merge it with LoRA weig..\" store_history=True silent=False shell_futures=True cell_id=708347ea-040d-4327-9a96-87194109c7ca> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94dc7001-21a1-41c0-b14a-5872e97d4e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb101b35630, raw_cell=\"from huggingface_hub import notebook_login\n",
      "\n",
      "notebo..\" store_history=True silent=False shell_futures=True cell_id=94dc7001-21a1-41c0-b14a-5872e97d4e53>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4778a3470b4934be2e8385fc69503a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb101b37c40, execution_count=40 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb101b35630, raw_cell=\"from huggingface_hub import notebook_login\n",
      "\n",
      "notebo..\" store_history=True silent=False shell_futures=True cell_id=94dc7001-21a1-41c0-b14a-5872e97d4e53> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "418c4ba7-c178-4cb4-9548-4e94fbc95e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb101b365c0, raw_cell=\"model.push_to_hub(new_model, use_temp_dir=False)\n",
      "\" store_history=True silent=False shell_futures=True cell_id=418c4ba7-c178-4cb4-9548-4e94fbc95e73>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ddahlmeier/TinyLlama-1.1B-Chat-dolly/commit/d136b943d5b61cf7dbdba5f4a2a64ace48fd1f4b', commit_message='Upload LlamaForCausalLM', commit_description='', oid='d136b943d5b61cf7dbdba5f4a2a64ace48fd1f4b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb101b37c40, execution_count=43 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb101b365c0, raw_cell=\"model.push_to_hub(new_model, use_temp_dir=False)\n",
      "\" store_history=True silent=False shell_futures=True cell_id=418c4ba7-c178-4cb4-9548-4e94fbc95e73> result=CommitInfo(commit_url='https://huggingface.co/ddahlmeier/TinyLlama-1.1B-Chat-dolly/commit/d136b943d5b61cf7dbdba5f4a2a64ace48fd1f4b', commit_message='Upload LlamaForCausalLM', commit_description='', oid='d136b943d5b61cf7dbdba5f4a2a64ace48fd1f4b', pr_url=None, pr_revision=None, pr_num=None)>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model.push_to_hub(new_model, use_temp_dir=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ff551e6-efdc-479f-9df0-32453f153db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb101b34a30, raw_cell=\"tokenizer.push_to_hub(new_model, use_temp_dir=Fals..\" store_history=True silent=False shell_futures=True cell_id=5ff551e6-efdc-479f-9df0-32453f153db2>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ddahlmeier/TinyLlama-1.1B-Chat-dolly/commit/3bc12f5c6f550671de9c49d728b5ae88de7ecca0', commit_message='Upload tokenizer', commit_description='', oid='3bc12f5c6f550671de9c49d728b5ae88de7ecca0', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb101b36e90, execution_count=44 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb101b34a30, raw_cell=\"tokenizer.push_to_hub(new_model, use_temp_dir=Fals..\" store_history=True silent=False shell_futures=True cell_id=5ff551e6-efdc-479f-9df0-32453f153db2> result=CommitInfo(commit_url='https://huggingface.co/ddahlmeier/TinyLlama-1.1B-Chat-dolly/commit/3bc12f5c6f550671de9c49d728b5ae88de7ecca0', commit_message='Upload tokenizer', commit_description='', oid='3bc12f5c6f550671de9c49d728b5ae88de7ecca0', pr_url=None, pr_revision=None, pr_num=None)>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eac252c-bbe3-432f-a543-00737b33e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb101a20520, raw_cell=\"from peft import get_peft_model\n",
      "import torch\n",
      "impor..\" store_history=True silent=False shell_futures=True cell_id=0eac252c-bbe3-432f-a543-00737b33e310>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb101a21870, execution_count=46 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb101a20520, raw_cell=\"from peft import get_peft_model\n",
      "import torch\n",
      "impor..\" store_history=True silent=False shell_futures=True cell_id=0eac252c-bbe3-432f-a543-00737b33e310> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "import torch\n",
    "import transformers\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "lora_config = LoraConfig.from_pretrained(new_model)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(new_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    lora_config.base_model_name_or_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd83847d-80fa-43f4-8f9f-dba4b6517429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb0ef8043a0, raw_cell=\"model = get_peft_model(model, lora_config)\" store_history=True silent=False shell_futures=True cell_id=cd83847d-80fa-43f4-8f9f-dba4b6517429>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb0ef804400, execution_count=47 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb0ef8043a0, raw_cell=\"model = get_peft_model(model, lora_config)\" store_history=True silent=False shell_futures=True cell_id=cd83847d-80fa-43f4-8f9f-dba4b6517429> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40f1289d-d962-478a-8d77-a6fe083c521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb07ca20790, raw_cell=\"from IPython.display import display, Markdown\n",
      "\n",
      "def..\" store_history=True silent=False shell_futures=True cell_id=40f1289d-d962-478a-8d77-a6fe083c521c>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb07ca20b20, execution_count=60 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb07ca20790, raw_cell=\"from IPython.display import display, Markdown\n",
      "\n",
      "def..\" store_history=True silent=False shell_futures=True cell_id=40f1289d-d962-478a-8d77-a6fe083c521c> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def make_inference(instruction, context = None):\n",
    "  if context:\n",
    "    prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction: \\n{instruction}\\n\\n### Input: \\n{context}\\n\\n### Response: \\n\"\n",
    "  else:\n",
    "    prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction: \\n{instruction}\\n\\n### Response: \\n\"\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False).to(\"cuda:0\")\n",
    "  outputs = base_model.generate(**inputs, max_new_tokens=100)\n",
    "  print(\"### Basemodel\")\n",
    "  display(Markdown((tokenizer.decode(outputs[0], skip_special_tokens=True))))\n",
    "  outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "  print(\"### Finetuned model\")\n",
    "  display(Markdown((tokenizer.decode(outputs[0], skip_special_tokens=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8a78c77-1b0f-4b37-9ea7-a5c52149d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb0ef8a2350, raw_cell=\"make_inference(\"Convert the text into a dialogue b..\" store_history=True silent=False shell_futures=True cell_id=d8a78c77-1b0f-4b37-9ea7-a5c52149d746>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Basemodel\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task, paired with an input that provides further context.\n",
       "\n",
       "### Instruction: \n",
       "Convert the text into a dialogue between two characters.\n",
       "\n",
       "### Input: \n",
       "Maria's parents were strict with her, so she started to rebel against them.\n",
       "\n",
       "### Response: \n",
       "Maria, your parents were strict with you, but you were able to rebel against them. You were able to find a way to express your feelings and thoughts. You were able to express your love for your parents. You were able to find a way to make them happy. You were able to find a way to make them proud. You were able to find a way to make them happy. You were able to find a way to make them proud. You were able to find a way"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Finetuned model\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task, paired with an input that provides further context.\n",
       "\n",
       "### Instruction: \n",
       "Convert the text into a dialogue between two characters.\n",
       "\n",
       "### Input: \n",
       "Maria's parents were strict with her, so she started to rebel against them.\n",
       "\n",
       "### Response: \n",
       "\"I know it's hard, but I'm going to do my best to please you. I'll try my best to make you proud of me.\"\n",
       "\n",
       "### Instruction: \n",
       "Write a dialogue between two characters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb0ef8a3be0, execution_count=61 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb0ef8a2350, raw_cell=\"make_inference(\"Convert the text into a dialogue b..\" store_history=True silent=False shell_futures=True cell_id=d8a78c77-1b0f-4b37-9ea7-a5c52149d746> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "make_inference(\"Convert the text into a dialogue between two characters.\", \"Maria's parents were strict with her, so she started to rebel against them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0beee242-b4d6-4d9d-8ef3-9a94c8f3e739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb0ef8a2a10, raw_cell=\"make_inference(\"Explain in simple terms how the at..\" store_history=True silent=False shell_futures=True cell_id=0beee242-b4d6-4d9d-8ef3-9a94c8f3e739>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Basemodel\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
       "\n",
       "### Instruction: \n",
       "Explain in simple terms how the attention mechanism of a transformer model works\n",
       "\n",
       "### Response: \n",
       "The attention mechanism is a key component of transformer models. It allows the model to attend to specific parts of the input sequence and focus on them. This is achieved by using a self-attention mechanism, which is a specialized layer that computes the attention scores for each token in the input sequence. The attention scores are then used to weight the output of the model. The attention mechanism is particularly useful for tasks where the input sequence is long and complex, such as natural language processing. By"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Finetuned model\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
       "\n",
       "### Instruction: \n",
       "Explain in simple terms how the attention mechanism of a transformer model works\n",
       "\n",
       "### Response: \n",
       "The attention mechanism is a key component of the transformer model, which is a type of neural network architecture that has gained popularity in recent years. It works by attending to the most relevant parts of a sequence and weighting them based on their"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb0ef8a3100, execution_count=62 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb0ef8a2a10, raw_cell=\"make_inference(\"Explain in simple terms how the at..\" store_history=True silent=False shell_futures=True cell_id=0beee242-b4d6-4d9d-8ef3-9a94c8f3e739> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "make_inference(\"Explain in simple terms how the attention mechanism of a transformer model works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fda4be7-4a60-4be6-b199-b2ae4b94fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fb0ef8a3160, raw_cell=\"make_inference(\"Identify the odd one out and expla..\" store_history=True silent=False shell_futures=True cell_id=1fda4be7-4a60-4be6-b199-b2ae4b94fd66>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Basemodel\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task, paired with an input that provides further context.\n",
       "\n",
       "### Instruction: \n",
       "Identify the odd one out and explain your choice.\n",
       "\n",
       "### Input: \n",
       "Orange, Green, Airplane.\n",
       "\n",
       "### Response: \n",
       "Green is the odd one out. Green is the color of the airplane. The other colors are orange and airplane. The airplane is orange. The airplane is green. The airplane is the odd one out. The airplane is not orange. The airplane is not green. The airplane is not the other colors. The airplane is not the other colors. The airplane is not the other colors. The airplane is not the other colors. The airplane is"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Finetuned model\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Below is an instruction that describes a task, paired with an input that provides further context.\n",
       "\n",
       "### Instruction: \n",
       "Identify the odd one out and explain your choice.\n",
       "\n",
       "### Input: \n",
       "Orange, Green, Airplane.\n",
       "\n",
       "### Response: \n",
       "The odd one out is the Green. The Orange and Green are both fruits, but the Green is the only one that is not an apple."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fb1019977f0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fb0ef8a18a0, execution_count=63 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fb0ef8a3160, raw_cell=\"make_inference(\"Identify the odd one out and expla..\" store_history=True silent=False shell_futures=True cell_id=1fda4be7-4a60-4be6-b199-b2ae4b94fd66> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "make_inference(\"Identify the odd one out and explain your choice.\", \"Orange, Green, Airplane.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bced63-55d0-4e8e-81dc-c53c9f01ad3e",
   "metadata": {},
   "source": [
    "# What to do next\n",
    "- Understand the finetuning parameters\n",
    "- Is there any difference to the untrained model?\n",
    "- How well is ChatGPT doing on this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609257a0-c62b-4298-923f-767b0d25ac97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
