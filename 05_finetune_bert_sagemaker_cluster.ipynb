{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb9893b-1345-4455-93de-22266712998a",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker - finetune BERT model\n",
    "From https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1949021-9399-4d4a-924d-a6c6ec414607",
   "metadata": {},
   "source": [
    "# Development environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb2036-3ff1-4497-bf2e-f07800821f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets[s3]==2.17.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39027436-8a01-4d91-ad61-0d1c3377c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50c71c-93a9-4f2b-9474-27de09ee8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "# use sagemaker execution role which has been configured via IAM with required permissions \n",
    "role = \"arn:aws:iam::739723034235:role/service-role/SageMaker-ExecutionRole-20240119T141388\"\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970e23f-cd85-40ee-b966-4ca2d121f7d6",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230231a-2638-46a3-bec7-652032a154fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer used in preprocessing\n",
    "tokenizer_name = 'distilbert-base-uncased'\n",
    "\n",
    "# dataset used\n",
    "dataset_name = 'rotten_tomatoes'\n",
    "\n",
    "# s3 key prefix for the data\n",
    "s3_prefix = 'samples/datasets/' + dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba44785-363c-4c93-905b-6a1ead0230f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# train, validation and test dataset\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# select smaller subset for faster training\n",
    "train_dataset = train_dataset.shuffle().select(range(1000)) \n",
    "eval_dataset = eval_dataset.shuffle().select(range(100)) \n",
    "test_dataset = test_dataset.shuffle().select(range(100)) \n",
    "\n",
    "# tokenize dataset\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# set format for pytorch\n",
    "train_dataset =  train_dataset.rename_column(\"label\", \"labels\")\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "eval_dataset = eval_dataset.rename_column(\"label\", \"labels\")\n",
    "eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e964f-b5e6-4acb-ae83-e4c4621bcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "train_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "# save validation to s3\n",
    "validation_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/validation'\n",
    "eval_dataset.save_to_disk(validation_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d8c71-851e-44fe-b8b8-f1e2f8265838",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeade01-3850-4f24-9cce-1aedca1fa32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./scripts/train_sagemaker.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87fffd8-7879-45ab-9fe5-dc2f3e929c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 32,\n",
    "                 'learning_rate': 2e-5,\n",
    "                 'warmup_steps': 0,\n",
    "                 'model_name':'distilbert-base-uncased'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d40a37-159f-4401-9f11-820954084630",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='train_sagemaker.py',\n",
    "                            source_dir='./scripts',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            transformers_version='4.26',\n",
    "                            pytorch_version='1.13',\n",
    "                            py_version='py39',\n",
    "                            hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d9ced-2269-4be2-88a4-bb8658b31a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({'train': training_input_path, 'test': validation_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e10e2-70db-4344-ba12-dcf914046b79",
   "metadata": {},
   "source": [
    "# Deploy the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53265f0-ff61-4096-a77d-f8f54d098b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_estimator.deploy(1, \"ml.g4dn.xlarge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c8ec0-5a25-44d3-8e50-768fba3632ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_input= {\"inputs\":\" great movie\"}\n",
    "\n",
    "predictor.predict(sentiment_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd09047-2e89-43ea-a709-1815c44fed36",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f79c29-b480-4a47-98b3-bfa3a25c1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(label):\n",
    "    mapping = {'LABEL_0': 0, 'LABEL_1': 1}\n",
    "    return mapping[label]\n",
    "\n",
    "sentiment_input= {\"inputs\": test_dataset[\"text\"]}\n",
    "test_output = predictor.predict(sentiment_input)\n",
    "test_predictions = [map_labels(item['label']) for item in test_output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afebcf87-1dbc-4dd8-92a0-b888306d3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_dataset['label'], test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59b8ed-6d37-445e-851b-02b6d8e3f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show examples of review and labels\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Review\": test_dataset['text'],\n",
    "                   \"Gold label\": test_dataset['label'],\n",
    "                   \"Predicted label\": test_predictions})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614e972-5f1d-4e37-bbf0-53d046673390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688fcbcd-dd13-4215-9c88-70472c3eb39e",
   "metadata": {},
   "source": [
    "# What to try next\n",
    "- How does the experience using Sagemaker training job compare to running the training in a notebook? Which mode of working do you prefer and why?\n",
    "- Watch this workshop on Huggingface and AWS Sagemaker https://huggingface.co/docs/sagemaker/getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbce7e1-3244-4162-8230-d954319248cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
