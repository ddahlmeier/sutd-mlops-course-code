{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15f81e3-0976-4ff7-8ae1-ddb5fbdf1d94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Try out Amazon Bedrock\n",
    "In this short tutorial you prompt an LLM model on AWS Bedrock.\n",
    "\n",
    "It includes different example use cases for Travel & Hospitality using Amazon Bedrock.\n",
    "\n",
    "These sample use cases involve different tasks and prompt engeering techniques, as follows:\n",
    "\n",
    "1. **Generate recommendations based on metadata**\n",
    "- **Task**: Text Generation\n",
    "- **Prompt Technique**: Zero-shot\n",
    "2. **Estimate capacity for airlines or hotel properties based on historical data**\n",
    "- **Task**: Complex Reasoning\n",
    "- **Prompt Technique**: Chain-of-Thoughts (CoT)\n",
    "3. **Create a question answering assistant for customer service**\n",
    "- **Task**: Question Answering with Dialogue Asistant (without memory)\n",
    "- **Prompt Technique**: Few-shot\n",
    "4. **Summarize and classify content from media files transcription**\n",
    "- **Task**: Text Summarization & Text Classification\n",
    "- **Prompt Technique**: Zero-shot\n",
    "5. **Create splash pages describing upcoming promotions**\n",
    "- **Task**: Code Generation\n",
    "- **Prompt Technique**: Zero-shot\n",
    "\n",
    "Let's start by ensuring the Bedrock SDK is properly installed.\n",
    "\n",
    "We'll also install a few libraries required in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d5cb2-3c3a-4091-a11f-1df62d9e0d1d",
   "metadata": {},
   "source": [
    "Let's start by ensuring the Bedrock SDK is properly installed.\n",
    "\n",
    "We'll also install a few libraries required in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800edbd3-f31c-436c-93e4-a3e791c85549",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade boto3  # 1.36.21\n",
    "! pip install --upgrade botocore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3767a6-e9bb-4de4-a325-9d346b082402",
   "metadata": {},
   "source": [
    "Now we can import the libraries and setup the Bedrock client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7bee6e-7ba5-4b81-9318-c0b857b4ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-east-1\")\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5ecac-8a9d-42b8-b1c7-8ecad5610314",
   "metadata": {},
   "source": [
    "Let's get the list of Foundational Models supported in Bedrock at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10722be-2f83-4f8c-89a4-7d9b181029f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b05c03-98a6-4fc1-a288-1e43326383fe",
   "metadata": {},
   "source": [
    "We will define an utility function for calling Bedrock.\n",
    "\n",
    "This will help passing the proper body depending on the model invoked, and will store the results in a CSV file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968017bf-c186-4897-8a38-ecdbe276b6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_bedrock(modelId, prompt_data):\n",
    "    if 'amazon' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"inputText\": prompt_data,\n",
    "            \"textGenerationConfig\":\n",
    "            {\n",
    "                \"maxTokenCount\":4096,\n",
    "                \"stopSequences\":[],\n",
    "                \"temperature\":0,\n",
    "                \"topP\":0.9\n",
    "            }\n",
    "        })\n",
    "        #modelId = 'amazon.titan-text-lite-v1'\n",
    "    elif 'anthropic' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 4096,\n",
    "            \"temperature\": 0,\n",
    "            \"top_k\":250,\n",
    "            \"top_p\":0.9,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": prompt_data}]\n",
    "                }\n",
    "            ],\n",
    "        })\n",
    "        #modelId = 'anthropic.claude-v2:1'\n",
    "    else:\n",
    "        print('Parameter model must be one of amazon titan or anthropic claude')\n",
    "        return\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    before = datetime.now()\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    latency = (datetime.now() - before)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    if 'amazon' in modelId:\n",
    "        response = response_body.get('results')[0].get('outputText')\n",
    "    elif 'anthropic' in modelId:\n",
    "        response = response_body.get('content')[0].get('text')\n",
    "    return response, latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa97f20-81c4-426c-b867-8400be5aea33",
   "metadata": {},
   "source": [
    "Now we are ready for running our examples with different models.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad9ab5-e0ef-4741-b305-36053150e2c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Generate recommendations based on metadata\n",
    "\n",
    "**Use Case:** A company wants to generate recommendations of flight destinations for their users based on some metadata, e.g. country, age-range, and interests.\n",
    "\n",
    "**Task:** Text Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d9a5e-bb64-4af1-95dc-56f8a6ff3990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human:\n",
    "Generate a list of 10 recommended Melia Hotels for traveling considering the information in the <metadata></metadata> XML tags, and include a very brief description of each recommendation.\n",
    "Answer in English.\n",
    "\n",
    "<metadata>\n",
    "Traveler going to Spain\n",
    "Age range between 20-30\n",
    "Interested on water sports and theme parks\n",
    "Traveling during the summer\n",
    "</metadata>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebf06a-1cf5-450c-953e-1cd1abe70f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v2:1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847647f-94e4-4a47-9cd2-2609af023546",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde01ec0-52c2-471e-aaf4-b4803085f162",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Estimate capacity for airlines or hotel properties based on historical data\n",
    "\n",
    "**Use Case:** A T&H company wants to estimate capacity/occupancy levels they could have for the next days based on historical information and flights/hotels metadata.\n",
    "\n",
    "**Task:** Complex Reasoning\n",
    "\n",
    "**Prompt Technique:** Chain-of-Thoughts (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8993b8-2772-4c33-b17b-7fbddb9b7e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human: Last week, the number of guests at 3 Melia hotels was as follows:\n",
    "- Monday: Paris 650, New York 320, Singapore 415\n",
    "- Tuesday: Paris 640, New York 330, Singapore 410\n",
    "- Wednesday: Paris 630, New York 340, Singapore 425\n",
    "\n",
    "Question: How many guests can we expect next Friday at the Paris hotel?\n",
    "Answer: Based on the numbers given and without any further information, there is a daily decrease of 10 guests for the Paris hotel.\n",
    "If we assume that this trend will continue for the next few days, we can expect 620 guests for the next day, which is Thursday, and\n",
    "therefore, 610 guests for Friday.\n",
    "\n",
    "Question: How many guests can we expect on Saturday at each of the hotels?\n",
    "Give a step-by-step reasoning and recommendations for increasing the number of guests at the hotels.\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8bc44-aa79-4bbd-b5b7-52be3c0f51d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v2:1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253149f-ae27-42d0-a36c-bd07fc22264c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f45c25-cb45-4d9d-8cb1-29b3547483b3",
   "metadata": {},
   "source": [
    "## 3. Create a question answering assistant for customer service\n",
    "\n",
    "**Use Case:** A company wants to create a bot capable of answering questions about the services available, based on the internal information for these.\n",
    "\n",
    "**Task:** Question Answering with Dialogue Asistant (no memory)\n",
    "\n",
    "**Prompt Technique:** Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cc7e9-876e-4d77-99cd-099439033148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Context: An airline services available for purchase are as follows\n",
    "1. Seat upgrades, available from 20 Euros, to classes Economy Plus and Business, on weekdays' flights\n",
    "2. Meals, available for payment in-flight, mediterranean menu, on all days' flights\n",
    "3. Fast boarding, from 30 Euros, available for premier customers, on all days' flights\n",
    "\n",
    "Instruction: Answer any questions about the services available in a friendly manner. If you don't know the answer just say 'Apologies, but I don't have the answer for that. Please contact our team by phone.'\n",
    "\n",
    "Assistant: Welcome to Airline Services, how can I help you?\n",
    "Human: Hi, I would like to know what are the services available please.\n",
    "Assistant: Of course, right now we have the seat upgrades, the meals, and the fast boarding.\n",
    "Human: Thank you. I would like to know details for those please.\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae8a78-c7d2-470d-82da-8f08677cb469",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v2:1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130aa69b-0ec0-4837-a019-fb16fca9fb0e",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80a21f-7987-40d0-b923-193c72367f7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Generate content summary based on transcriptions from media files\n",
    "\n",
    "**Use Case:** A company needs to generate summaries of the audio transcription for audio and video files for customer service, to be sent to their operations quality team. They also want to classify this content according to specific categories.\n",
    "\n",
    "**Task:** Text Summarization & Text Classification\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374d510-d20d-4820-96d6-156977876859",
   "metadata": {},
   "source": [
    "#### (Pre-requisite)\n",
    "\n",
    "First, we will need to transcribe the media files. You can e.g. use Amazon Transcribe for this task following examples like this: https://docs.aws.amazon.com/code-library/latest/ug/transcribe_example_transcribe_StartTranscriptionJob_section.html\n",
    "\n",
    "For our sample we will start from an interview transcription in the file \"interview.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa1e2c-6de3-4b24-805f-2090fd7909b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"interview.txt\", \"r\").read()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6dea9-7ae5-42ae-8195-b670e36d1482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =f\"\"\"\n",
    "Human:\n",
    "Generate a summary of the transcription in the <transcription></transcription> XML tags below.\n",
    "Then, classify the mood of the participants according to the closest category within 'fully satisfied', 'satisfied', 'unsatisfied', 'fully unsatisfied', or 'neutral'.\n",
    "\n",
    "<transcription>\n",
    "{f}\n",
    "</transcription>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b5b1d-d553-4526-8892-ec9f4570f731",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v2', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d09320-6f1e-4596-8f51-55dfc0b127d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410031e-d47f-485f-b83e-cbdbbb2fa42b",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d617cee-a8e9-4728-b821-6ebf2c6d51fc",
   "metadata": {},
   "source": [
    "## 5. Create splash pages describing upcoming promotions\n",
    "\n",
    "**Use Case:** A company wants to create HTML pages quickly and easily for their upcoming promotions.\n",
    "\n",
    "**Task:** Code Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248a2a2-687b-40c5-aeed-e183bd181b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "There is an upcoming promotion presented by the Melia Salou Hotel.\n",
    "The promotion is targeting young audience in the age range between 18 and 40.\n",
    "The promotion consists of a 20% discount when booking rooms online.\n",
    "There will be additional fees for upgrades and bookings can be done trought this same portal.\n",
    "The promotion is part of the Summer Discounts of the company.\n",
    "The promotion is available from June 28th to August 31st.\n",
    "\n",
    "Based the this information, generate the HTML code for an attractive splash page for this promotion.\n",
    "Include catchy phrases and invite customers to sign-up for the Melia Hotel's loyalty program.\n",
    "Have the splash page use blue fonts and black background, according to the hotel's branding.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4a927-6e7a-49fd-b253-6ee555b17fbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v2', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6f2f2-601e-4da8-bf2f-ec1ef4840faf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c45ec6-8934-4a2e-a53c-03ffa81ddd31",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
