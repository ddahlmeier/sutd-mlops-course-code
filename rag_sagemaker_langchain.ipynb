{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa97e7-f4e3-48f0-a508-6178acccea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/generative-ai-on-aws/generative-ai-on-aws/blob/main/09_rag/01_langchain_llama2_sagemaker.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c792b6-9fd9-4287-ab49-8cd131aaff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b5720-1230-46cb-aac6-a7597eb57a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import faiss\n",
    "import pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5b2dd-b0f6-4a02-8980-e7ff1f6fbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching data\n",
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    dict(year=2022, source=filenames[0]),\n",
    "    dict(year=2021, source=filenames[1]),\n",
    "    dict(year=2020, source=filenames[2]),\n",
    "    dict(year=2019, source=filenames[3])]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625f2af-2cfd-429d-8d43-863dd145c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last pages which are original 1997 letter to shareholder\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import glob\n",
    "\n",
    "local_pdfs = glob.glob(data_root + '*.pdf')\n",
    "\n",
    "for local_pdf in local_pdfs:\n",
    "    pdf_reader = PdfReader(local_pdf)\n",
    "    pdf_writer = PdfWriter()\n",
    "    for pagenum in range(len(pdf_reader.pages)-3):\n",
    "        page = pdf_reader.pages[pagenum]\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    with open(local_pdf, 'wb') as new_file:\n",
    "        new_file.seek(0)\n",
    "        pdf_writer.write(new_file)\n",
    "        new_file.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e05e6c-6bcc-4fc2-94a9-e5197d59fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "for idx, file in enumerate(filenames):\n",
    "    loader = PyPDFLoader(data_root + file)\n",
    "    document = loader.load()\n",
    "    for document_fragment in document:\n",
    "        document_fragment.metadata = metadata[idx]\n",
    "        \n",
    "    documents += document\n",
    "\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'# of Document Pages {len(documents)}')\n",
    "print(f'# of Document Chunks: {len(docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708fd76-5c5e-48ee-885f-2f61f0a9828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "# default instance is ml.g5.2xlarge\n",
    "embedding_model_id, embedding_model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"*\"\n",
    "model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version)\n",
    "\n",
    "embedding_predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6447b99-0694-47da-94cf-644d5fb7c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the model endpoint NAME, not the ARN\n",
    "embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
    "embedding_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df16d2d-3123-4ef6-95ba-55d4eb821f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3720206-24d7-4828-af69-b20d22ef9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "import json\n",
    "\n",
    "\n",
    "class CustomEmbeddingsContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"embedding\"]\n",
    "\n",
    "\n",
    "embeddings_content_handler = CustomEmbeddingsContentHandler()\n",
    "\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name=embedding_model_endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    content_handler=embeddings_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49ba0e-fb48-4e6b-ab61-4111c11ab95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18422b7-477d-44da-aac5-31006b479559",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b009093-9d53-4e57-babe-9b3f3adfc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How has AWS evolved?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79735868-836b-4217-84c5-4712b09718ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_scores = db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78ca6e-0766-4bd5-89f9-00095de9cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter={\"year\": 2022}\n",
    "\n",
    "results_with_scores = db.similarity_search_with_score(query,\n",
    "  filter=filter)\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4c48c-edf8-41f6-bb90-b1e4a6c6aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Use the context provided to answer the question at the end. If you dont know the answer just say that you don't know, don't try to make up an answer.\n",
    "<</SYS>>\n",
    "\n",
    "Context:\n",
    "----------------\n",
    "{context}\n",
    "----------------\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c41ca-ea4a-45d1-a0d1-82b5a579ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "import json\n",
    "\n",
    "\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps(\n",
    "            {\"inputs\" : [\n",
    "                [\n",
    "                    {\n",
    "                        \"role\" : \"system\",\n",
    "                        \"content\" : \"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\" : \"user\",\n",
    "                        \"content\" : prompt\n",
    "                    }\n",
    "                ]],\n",
    "                \"parameters\" : {**model_kwargs}\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generation\"][\"content\"]\n",
    "\n",
    "qa_content_handler = QAContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff907d8d-a0e7-4b9a-b18c-d0a07c0bc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"2.*\"\n",
    "llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version)\n",
    "llm_predictor = llm_model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079cc7e-0309-429b-a2f0-73c230eed2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the model endpoint NAME, not the ARN\n",
    "llm_model_endpoint_name = llm_predictor.endpoint_name\n",
    "llm_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554166c-a61d-4d66-8ff7-6e6bdcaa9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "        endpoint_name=llm_model_endpoint_name,\n",
    "        region_name=aws_region,\n",
    "        model_kwargs={\"max_new_tokens\": 1000, \"top_p\": 0.9, \"temperature\": 1e-11},\n",
    "        endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "        content_handler=qa_content_handler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125ad86-f8f5-4f39-a3c5-ccca367563f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Will Jeff Besos come back as CEO?\"\n",
    "llm.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda70ed-7796-4a21-b34f-7d73061710c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "#Delete embedding endpoint\n",
    "sagemaker_client.delete_endpoint(EndpointName=embedding_model_endpoint_name)\n",
    "\n",
    "#Delete llm endpoint\n",
    "sagemaker_client.delete_endpoint(EndpointName=llm_model_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4e3f9-98f3-47b7-9570-e491ef50d5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
